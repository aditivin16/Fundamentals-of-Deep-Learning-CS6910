{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVBxH1dXqIyc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder  # For label encoding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw2x8tLjr92-",
        "outputId": "89af3249-c1e2-4111-bdec-bd3049290a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkBnFGIGsu3z",
        "outputId": "19552cc9-36d8-4979-e595-8548e42b23fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5600, 2)\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/POS/train.csv\")\n",
        "print(df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcnQeOuw4DTW"
      },
      "outputs": [],
      "source": [
        "# tokenizer for sentences\n",
        "tokens_ip = df_train['Sentence'].values\n",
        "tokenizer_ip = Tokenizer()\n",
        "tokenizer_ip.fit_on_texts(tokens_ip)\n",
        "word_index_ip = tokenizer_ip.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GPfwqQBIhoA"
      },
      "outputs": [],
      "source": [
        "# tokeniszer for tags\n",
        "tokens_op = df_train['Tags'].values\n",
        "tokenizer_op = Tokenizer()\n",
        "tokenizer_op.fit_on_texts(tokens_op)\n",
        "word_index_op = tokenizer_op.word_index\n",
        "max_sequence_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pyuwn9ufqRUl"
      },
      "outputs": [],
      "source": [
        "# function to preprocess input data\n",
        "def preprocess(df):\n",
        "  sentence = df['Sentence'].values\n",
        "  tags = df['Tags'].values\n",
        "\n",
        "  # Tokenize the text data\n",
        "  seq_sent = tokenizer_ip.texts_to_sequences(sentence)\n",
        "  seq_tags = tokenizer_op.texts_to_sequences(tags)\n",
        "\n",
        "  # Pad the sequences to ensure uniform length\n",
        "  max_sequence_length = max([len(x) for x in seq_sent ])\n",
        "\n",
        "  input = pad_sequences(seq_sent, maxlen=max_sequence_length)\n",
        "  desired_op = pad_sequences(seq_tags, maxlen=max_sequence_length)\n",
        "\n",
        "  desired_op = np.stack([to_categorical(i, num_classes=len(tokenizer_op.word_index) + 1) for i in desired_op])\n",
        "  return input, desired_op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OETHP0Ir1Gb",
        "outputId": "edfeabff-99a4-4052-bb59-53d9a028f910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-23 08:43:10--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2025-04-23 08:45:49 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get GloVe\n",
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fnuY1dvp0IMm"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 200  # GloVe 200D embeddings\n",
        "embeddings_index = {}\n",
        "\n",
        "# Read the GloVe file and store the embeddings\n",
        "with open('glove.6B.200d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lz3bFzLPqhdI"
      },
      "outputs": [],
      "source": [
        "# Making embedding matrix\n",
        "embedding_matrix = np.zeros((len(word_index_ip) + 1, embedding_dim))\n",
        "for word, i in word_index_ip.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "slYaRUgbwthf"
      },
      "outputs": [],
      "source": [
        "# rrn object for pos\n",
        "\n",
        "class RNNModel:\n",
        "    def __init__(self, word_index, embedding_matrix, tag_tokenizer, embedding_dim=200, max_sequence_length=100):\n",
        "        \"\"\"\n",
        "        Initializes the POS RNN model.\n",
        "\n",
        "        word_index: The word index from a tokenizer (mapping words to integer indices)\n",
        "        embedding_matrix: The pre-trained GloVe embeddings matrix\n",
        "        tag_tokenizer: The tokenizer for POS tags (used for one-hot encoding the tags)\n",
        "        embedding_dim: The dimension of the GloVe embeddings (default is 200)\n",
        "        max_sequence_length: The maximum length of the sentences (default is 100)\n",
        "        \"\"\"\n",
        "        self.word_index = word_index\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.tag_tokenizer = tag_tokenizer\n",
        "        self.num_tags = len(tag_tokenizer.word_index) + 1  # Number of unique POS tags\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        # Add the embedding layer with pre-trained GloVe embeddings\n",
        "        model.add(Embedding(input_dim=len(self.word_index) + 1,\n",
        "                            output_dim=self.embedding_dim,\n",
        "                            weights=[self.embedding_matrix],\n",
        "                            input_length=self.max_sequence_length,\n",
        "                            trainable=False))  # Freezing the embeddings\n",
        "\n",
        "        # Add the SimpleRNN layer\n",
        "        model.add(SimpleRNN(25, return_sequences=True, dropout=0.0, recurrent_dropout=0.0))\n",
        "\n",
        "        # Add the output layer (one-hot encoded POS tags)\n",
        "        model.add(Dense(self.num_tags, activation='softmax'))\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"\n",
        "        Returns the built model.\n",
        "        \"\"\"\n",
        "        return self.model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "44qss0Rlw6eJ",
        "outputId": "f1818421-4a19-46f0-fa26-9cfd69cc0b63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.6499 - loss: 1.6918\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8921 - loss: 0.4471\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9088 - loss: 0.3615\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9160 - loss: 0.3247\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9204 - loss: 0.2994\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9244 - loss: 0.2806\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9252 - loss: 0.2735\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.9271 - loss: 0.2624\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9297 - loss: 0.2519\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9298 - loss: 0.2484\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc1d0b60850>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn_model = RNNModel(word_index=tokenizer_ip.word_index,\n",
        "                             embedding_matrix=embedding_matrix,\n",
        "                             tag_tokenizer= tokenizer_op,\n",
        "                             embedding_dim=200,\n",
        "                             max_sequence_length=max_sequence_length)\n",
        "\n",
        "# Get the model\n",
        "pos_model = rnn_model.get_model()\n",
        "\n",
        "#preprocess training data\n",
        "input_train, desired_op_train = preprocess(df_train)\n",
        "\n",
        "# train model\n",
        "pos_model.fit(input_train, desired_op_train, epochs=10, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lXXGUWvhzE26",
        "outputId": "84df92a9-b286-484e-ca87-45b487e35d4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8717 - loss: 0.5199\n",
            "0.5098825693130493 0.8743162155151367\n"
          ]
        }
      ],
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/POS/test.csv\")\n",
        "input_test, desired_op_test = preprocess(df_test)\n",
        "loss, accuracy = pos_model.evaluate(input_test, desired_op_test)\n",
        "print( loss, accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
